# -*- coding: utf-8 -*-
"""ExerciceXPW4D4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HJAAgk7IJNjm6nPEGY93EnuRMb0PzCth
"""

from google.colab import files

files.upload()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

data = pd.read_csv("household_power_consumption.txt", sep=';', parse_dates={'datetime': ['Date', 'Time']}, infer_datetime_format=True, low_memory=False, na_values=['?'], index_col='datetime')

print(data.head())
print(data.dtypes)
print(data.shape)

data = data.astype(float)
data.fillna(data.mean(), inplace=True)
print(data.isnull().sum())

data_resampled = data['Global_active_power'].resample('D').agg(['sum', 'mean'])
data_resampled.plot(subplots=True, figsize=(10, 6), title='Global Active Power (Daily)')
plt.show()

data_resampled_intensity = data['Global_intensity'].resample('D').agg(['mean', 'std'])
data_resampled_intensity.plot(y=['mean', 'std'], figsize=(10, 6), title='Global Intensity (Daily Mean & Std)')
plt.show()

scaler = MinMaxScaler()
data_scaled = scaler.fit_transform(data)
train_size = int(len(data_scaled) * 0.8)
train, test = data_scaled[:train_size], data_scaled[train_size:]

def create_sequences(data, seq_length=10):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i+seq_length])
        y.append(data[i+seq_length, 0])
    return np.array(X), np.array(y)

seq_length = 10
X_train, y_train = create_sequences(train, seq_length)
X_test, y_test = create_sequences(test, seq_length)

X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2]))

model = Sequential([
    LSTM(50, return_sequences=True, input_shape=(seq_length, data.shape[1])),
    LSTM(50, return_sequences=False),
    Dense(25),
    Dense(1)
])

model.compile(optimizer='adam', loss='mse')
model.summary()

history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=32)

plt.figure(figsize=(10, 5))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.title('Loss over epochs')
plt.show()