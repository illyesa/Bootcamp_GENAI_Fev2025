{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) A companyâ€™s financial reports stored in an Excel file : Structured Data (Excel files often contain organized, tabular data with predefined formats)\n",
    "\n",
    "# 2) Photographs uploaded to a social media platform : Unstructured Data (Images do not have a predefined format or structure)\n",
    "\n",
    "# 3) A collection of news articles on a website : Unstructured Data (Text articles are not stored in a structured, tabular form)\n",
    "\n",
    "# 4) Inventory data in a relational database : Structured Data (Relational databases follow a strict schema with tables, rows, and columns)\n",
    "\n",
    "# 5) Recorded interviews from a market research study : Unstructured Data (Audio or video recordings do not follow a structured format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) A series of blog posts about travel experiences : Convert to Structured Data Using Natural Language Processing (NLP)\n",
    "\n",
    "# Using NLP techniques to extract key details (location, date, activities, experiences...)\n",
    "# Store the extracted information in a structured database with fields like Post_ID, Author, Date, Location, Keywords, experiences...\n",
    "# This allows for easier querying and analysis of trends in travel experiences\n",
    "\n",
    "# 2) Audio recordings of customer service calls : Convert Using Speech-to-Text (STT) and NLP\n",
    "\n",
    "# Apply STT to transcribe\n",
    "# Use NLP to structure the data, identifying Customer_ID, Date, Keywords, Issue_Category...\n",
    "\n",
    "# 3) Handwritten notes from a brainstorming session : Convert Using Optical Character Recognition (OCR) and NLP\n",
    "\n",
    "# Scan and process the handwritten notes using OCR\n",
    "# Use NLP techniques to categorize ideas into structured formats like Topic, Idea_Description...\n",
    "\n",
    "# 4) A video tutorial on cooking : Convert Using Video Analysis and Metadata Extraction\n",
    "\n",
    "# Use speech-to-text (STT) for spoken instructions\n",
    "# Apply computer vision to recognize key ingredients and cooking steps\n",
    "# Extract metadata like Recipe_Name, Ingredients, Cooking_Steps, Duration, Chef_Name... store in a structured recipe database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dt = pd.read_csv(\"train.csv\")\n",
    "print(dt.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   5.1  3.5  1.4  0.2  Iris-setosa\n",
      "0  4.9  3.0  1.4  0.2  Iris-setosa\n",
      "1  4.7  3.2  1.3  0.2  Iris-setosa\n",
      "2  4.6  3.1  1.5  0.2  Iris-setosa\n",
      "3  5.0  3.6  1.4  0.2  Iris-setosa\n",
      "4  5.4  3.9  1.7  0.4  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "di = pd.read_csv(\"Iris_dataset.csv\")\n",
    "print(di.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name  Age       City\n",
      "0   N1   25      Paris\n",
      "1   N2   30    Bordeau\n",
      "2   N3   27  Marseille\n",
      "DataFrame exported in xlsx data.xlsx\n",
      "DataFrame exported in json data.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Name\": [\"N1\", \"N2\", \"N3\"],\n",
    "    \"Age\": [25, 30, 27],\n",
    "    \"City\": [\"Paris\", \"Bordeau\", \"Marseille\"]\n",
    "}\n",
    "df_data = pd.DataFrame(data)\n",
    "print(df_data.head())\n",
    "\n",
    "excel_name = \"data.xlsx\"\n",
    "df_data.to_excel(excel_name, index=False)\n",
    "print(f\"DataFrame exported in xlsx {excel_name}\")\n",
    "\n",
    "json_name = \"data.json\"\n",
    "df_data.to_json(json_name, orient=\"records\")\n",
    "print(f\"DataFrame exported in json {json_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  id                                              title  \\\n",
      "0       1   1  sunt aut facere repellat provident occaecati e...   \n",
      "1       1   2                                       qui est esse   \n",
      "2       1   3  ea molestias quasi exercitationem repellat qui...   \n",
      "3       1   4                               eum et est occaecati   \n",
      "4       1   5                                 nesciunt quas odio   \n",
      "\n",
      "                                                body  \n",
      "0  quia et suscipit\\nsuscipit recusandae consequu...  \n",
      "1  est rerum tempore vitae\\nsequi sint nihil repr...  \n",
      "2  et iusto sed quo iure\\nvoluptatem occaecati om...  \n",
      "3  ullam et saepe reiciendis voluptatem adipisci\\...  \n",
      "4  repudiandae veniam quaerat sunt sed\\nalias aut...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"https://github.com/devtlv/Datasets-DA-Bootcamp-2-/raw/refs/heads/main/Week%204%20-%20Data%20Understanding/W4D3%20-%20Importing%20Data,%20Exporting%20D/posts.zip\")\n",
    "\n",
    "print(df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
